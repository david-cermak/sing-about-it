from kokoro import KPipeline
from IPython.display import display, Audio
import soundfile as sf
import torch
from pydub import AudioSegment
import io
# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English
# ðŸ‡ªðŸ‡¸ 'e' => Spanish es
# ðŸ‡«ðŸ‡· 'f' => French fr-fr
# ðŸ‡®ðŸ‡³ 'h' => Hindi hi
# ðŸ‡®ðŸ‡¹ 'i' => Italian it
# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]
# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br
# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]
pipeline = KPipeline(lang_code='a') # <= make sure lang_code matches voice, reference above.

# This text is for demonstration purposes only, unseen during training
text = '''
The rise of quantum computing threatens all current public-key schemes (RSA, ECC, etc.). Shorâ€™s
algorithm can break these by efficiently solving factorization or discrete-logarithm problems, so
â€œharvest-now, decrypt-laterâ€ attacks could expose long-lived IoT data once quantum hardware
matures. Embedded devices (sensors, controllers, smart cards) often use weaker crypto already
and remain in service for many years, so upgrading to quantum-resistant algorithms is essential.
However, post-quantum (PQ) schemes typically have higher cost: larger key or signature sizes and
more computation . Constrained platforms (e.g. ARM Cortexâ€‘M, RISCâ€‘V micros) must balance security
against limited RAM/Flash, CPU speed, and energy. For example, a reference PQ library implementation
of CRYSTALSâ€‘Kyber-512 on a 24â€¯MHz Cortexâ€‘M4 required â‰ˆ0.65â€¯M CPU cycles for keygen and â‰ˆ0.96â€¯M
for decapsulation, using ~9â€¯KB RAM . Highly optimized assembly (â€œM4â€) cuts this roughly in half and
reduces RAM to ~2.5â€¯KB . In contrast, a hash-based signature like SPHINCS+ can take tens of
seconds to minutes to generate a signature on the same MCU , making it impractical for many IoT
uses. Thus, embedded PQC requires careful algorithm choice and implementation.
'''
# text = 'ã€Œã‚‚ã—ãŠã‚ŒãŒãŸã å¶ç„¶ã€ãã—ã¦ã“ã†ã—ã‚ˆã†ã¨ã„ã†ã¤ã‚‚ã‚Šã§ãªãã“ã“ã«ç«‹ã£ã¦ã„ã‚‹ã®ãªã‚‰ã€ã¡ã‚‡ã£ã¨ã°ã‹ã‚Šçµ¶æœ›ã™ã‚‹ã¨ã“ã‚ã ãªã€ã¨ã€ãã‚“ãªã“ã¨ãŒå½¼ã®é ­ã«æ€ã„æµ®ã‹ã‚“ã ã€‚'
# text = 'ä¸­åœ‹äººæ°‘ä¸ä¿¡é‚ªä¹Ÿä¸æ€•é‚ªï¼Œä¸æƒ¹äº‹ä¹Ÿä¸æ€•äº‹ï¼Œä»»ä½•å¤–åœ‹ä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒæ‹¿è‡ªå·±çš„æ ¸å¿ƒåˆ©ç›Šåšäº¤æ˜“ï¼Œä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒåžä¸‹æå®³æˆ‘åœ‹ä¸»æ¬Šã€å®‰å…¨ã€ç™¼å±•åˆ©ç›Šçš„è‹¦æžœï¼'
# text = 'Los partidos polÃ­ticos tradicionales compiten con los populismos y los movimientos asamblearios.'
# text = 'Le dromadaire resplendissant dÃ©ambulait tranquillement dans les mÃ©andres en mastiquant de petites feuilles vernissÃ©es.'
# text = 'à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤ªà¥‹à¤°à¥à¤Ÿà¤°à¥‹à¤‚ à¤•à¥€ à¤¹à¤¡à¤¼à¤¤à¤¾à¤² à¤²à¤—à¤¾à¤¤à¤¾à¤° à¤ªà¤¾à¤‚à¤šà¤µà¥‡à¤‚ à¤¦à¤¿à¤¨ à¤œà¤¾à¤°à¥€, à¤¦à¤¿à¤¸à¤‚à¤¬à¤° à¤¸à¥‡ à¤‡à¤²à¥‡à¤•à¥à¤Ÿà¥à¤°à¥‰à¤¨à¤¿à¤• à¤Ÿà¥‹à¤² à¤•à¤²à¥‡à¤•à¥à¤¶à¤¨à¤² à¤¸à¤¿à¤¸à¥à¤Ÿà¤®'
# text = "Allora cominciava l'insonnia, o un dormiveglia peggiore dell'insonnia, che talvolta assumeva i caratteri dell'incubo."
# text = 'Elabora relatÃ³rios de acompanhamento cronolÃ³gico para as diferentes unidades do Departamento que propÃµem contratos.'

# Clean the text by removing newlines and extra whitespace
text = ' '.join(text.split())

# Split text into sentences to handle length limits while maintaining coherence
import re
sentences = re.split(r'[.!?]+', text)
sentences = [s.strip() for s in sentences if s.strip()]

print(f"Processing {len(sentences)} sentences...")

# 4ï¸âƒ£ Generate audio for each sentence and concatenate into single file
all_audio_segments = []
all_generated_text = []

for i, sentence in enumerate(sentences):
    print(f"Processing sentence {i+1}/{len(sentences)}: {sentence[:50]}...")

    generator = pipeline(
        sentence, voice='af_heart', # <= change voice here
        speed=1
    )

    # Generate audio for this sentence
    gs, ps, audio = next(generator)
    all_audio_segments.append(audio)
    all_generated_text.append(gs)
    print(f"Generated: {gs}")

# Concatenate all audio segments
import numpy as np
complete_audio = np.concatenate(all_audio_segments)

# Display and save the complete audio
print("Complete generated text:", ' '.join(all_generated_text))
display(Audio(data=complete_audio, rate=24000, autoplay=True))

# Save as WAV file
sf.write('output.wav', complete_audio, 24000)

# Convert to MP3 using pydub
# First, save the numpy array to a temporary WAV file in memory
temp_wav = io.BytesIO()
sf.write(temp_wav, complete_audio, 24000, format='WAV')
temp_wav.seek(0)

# Load with pydub and export as MP3
audio_segment = AudioSegment.from_wav(temp_wav)
audio_segment.export('output.mp3', format='mp3', bitrate='192k')

print("Audio saved as 'output.wav' and 'output.mp3'")
